#%% import libraries
import pandas as pd
from swmm.toolkit.shared_enum import NodeAttribute
from pyswmm import Simulation, Output
from _inputs import *
from _utils import *


# define files
# define folders
fldr_models = "D:/Dropbox/_GradSchool/_norfolk/stormy/stochastic_storm_transposition/_scratch/models/"
fldr_models_neg = fldr_models + "most_negative_interaction/"
fldr_models_neg_rivanna_jan2024 = fldr_models_neg + "models_exactly_as_they_are_on_rivanna/"
fldr_models_neg_rivanna_dec2023 = fldr_models_neg_rivanna_jan2024 + "original_results/"
fldr_models_neg_local_pyswmm = fldr_models_neg + "running_using_pyswmm/"
fldr_models_neg_local_PCSWMM = fldr_models_neg + "running_locally/"
#%% isolate events with negative interaction
df_watershed_flood_attribution_neg_inter = df_watershed_flood_attribution[df_watershed_flood_attribution.frac_interaction<0]
df_volumes = df_watershed_flood_attribution_neg_inter.loc[:,["flooding_cubic_meters_rainonly","flooding_cubic_meters_surgeonly", "flooding_cubic_meters_compound"]]

s_interaction = df_watershed_flood_attribution_neg_inter.flooding_cubic_meters_compound-(df_watershed_flood_attribution_neg_inter.flooding_cubic_meters_rainonly + df_watershed_flood_attribution_neg_inter.flooding_cubic_meters_surgeonly)
s_interaction = s_interaction*-1
s_interaction.name = "flooding_negative_cubic_meters_interaction"

df_volumes = pd.concat([df_volumes,s_interaction], axis = 1)

#%% manually investigating the event with the largest negative interaction
# find the index of the most negative interaction simulated
idx_largest_neg_inter = df_volumes.idxmax().flooding_negative_cubic_meters_interaction

df_largest_neg_interaction = df_watershed_flood_attribution.loc[idx_largest_neg_inter,:]

print("(realization, year, storm_id) = {}".format(idx_largest_neg_inter))

df_swmm_summaries = pd.read_csv(f_sst_event_summaries).set_index(["realization", "year", "storm_id"])

df_swmm_model_most_neg = df_swmm_summaries.loc[idx_largest_neg_inter,:]

def return_lst_outs(fldr):
    lst_outs = []
    for f in glob(fldr+"*"):
        if ".out" in f:
            lst_outs.append(f)
    return lst_outs

def return_lst_inps_and_outs(fldr):
    lst_inps = []
    lst_outs = []
    for f in glob(fldr+"*"):
        if ".inp" in f:
            lst_inps.append(f)
            f_out = f.split(".")[0]+".out"
            lst_outs.append(f_out)
    return lst_inps, lst_outs
#%% processing the local simulations
lst_pcswmm_out_path = return_lst_outs(fldr_models_neg_local_PCSWMM)

df_total_flooding_pcswmm = compute_total_node_flooding(lst_pcswmm_out_path)

#%% run simulations using pyswmm
lst_pyswmm_inp_path, lst_pyswmm_out_path = return_lst_inps_and_outs(fldr_models_neg_local_pyswmm)

from datetime import datetime
max_runtime_min = 15
run_sims = False

if run_sims:
    for f_inp in lst_pyswmm_inp_path:
        with Simulation(f_inp) as sim:
            sim_start_time = datetime.now()
            for step in sim:
                sim_time = datetime.now()
                sim_runtime_min = round((sim_time - sim_start_time).seconds / 60, 1)
                if sim_runtime_min > max_runtime_min:
                    problem = "User-defined maximum simulation time limit of {} minutes reached, so simulation was halted.".format(max_runtime_min)
                    print(problem)
                    # success = False
                    # break
                pass

df_total_flooding_pyswmm = compute_total_node_flooding(lst_pyswmm_out_path)

with Simulation(lst_pyswmm_inp_path[0]) as sim:
    print("SWMM engine used for pyswmm sims: {}".format(sim.engine_version))

import pyswmm
print("pyswmm version: {}".format(pyswmm.__version__))
#%% inspecting pcswmm results
print("Flood volumes in local PCSWMM simulation:")
df_total_flooding_pcswmm
#%% inspecting pyswmm results
print("Flood volumes in local pyswmm simulation:")
df_total_flooding_pyswmm

#%% inspecting output netcdf generated by the running_swmm script on Rivanna
print("Investigating the original runs on the Rivanna from back in December 2023")

f_ds_out =  fldr_models_neg_rivanna_dec2023 + "_model_outputs_year764.nc"

ds_out_from_rivanna = xr.open_dataset(f_ds_out)

df_total_flooding_neg_inter_rivanna = ds_out_from_rivanna.sum(dim = "node_id").to_dataframe()

df_total_flooding_neg_inter_rivanna = df_total_flooding_neg_inter_rivanna.reset_index()       

df_total_flooding_neg_inter_rivanna = classify_sims(df_total_flooding_neg_inter_rivanna)

df_total_flooding_neg_inter_rivanna.set_index(["realization", "year", "storm_id"]).sort_index().loc[(1,764,5),:]

#%% I re-ran the simulations on the Rivanna and re-generated the netcdf file and maintained the swmm .out files in Jan 2024
print("Inspecting model results re-run on the Rivanna on 1/17/2024")
f_ds_out = fldr_models_neg_rivanna_jan2024 + "_model_outputs_year764.nc"

ds_out_from_rivanna = xr.open_dataset(f_ds_out, engine = "netcdf4")

df_total_flooding_neg_inter_rivanna = ds_out_from_rivanna.sum(dim = "node_id").to_dataframe()

df_total_flooding_neg_inter_rivanna = df_total_flooding_neg_inter_rivanna.reset_index()       

df_total_flooding_neg_inter_rivanna = classify_sims(df_total_flooding_neg_inter_rivanna)

# print("Flood volumes in local simulation look fine:")
df_total_flooding_neg_inter_rivanna.set_index(["realization", "year", "storm_id"]).sort_index().loc[(1,764,5),:]

#%% now loading the .out files and inspecting them directly
print("Inspecting the .out files from the 1/17/24 model runs")

lst_rivanna_ins, lst_rivanna_outs = return_lst_inps_and_outs(fldr_models_neg_rivanna_jan2024)

df_total_flooding_neg_inter = compute_total_node_flooding(lst_rivanna_outs)
print("Flood volumes in 1/17/24 simulation directly from the .out files:")
df_total_flooding_neg_inter