"""
This script consolidates all of the rainfall time series generated by RainyDay
"""
#%% import libraries
from pathlib import Path
import xarray as xr
dask.config.set(**{'array.slicing.split_large_chunks': False}) 
import pandas as pd
from glob import glob
import time
import shutil
from __utils import *
import time

start_time = time.time()
year = str(sys.argv[1])
#%% define directories
fpath_strm_cats = dir_mrms_coarse + "mrms_{}/StormCatalog/*.nc".format(year)

f_ncs_coarse_catalog = glob(fpath_strm_cats)
f_ncs_fullres = glob(dir_fullres_rain + "/{}*.nc".format(year))

d_perf = {}
d_perf['success'] = False
#%% load year of fullres data
try:
    ds_fullres = xr.open_mfdataset(f_ncs_fullres, engine = "h5netcdf", chunks = {"longitude":700, "latitude":800})
    if (max(ds_fullres["longitude"].values) > 180) and (max(ds_fullres["longitude"].values) <= 360): # convert from positive degrees west to negative degrees west
        ds_fullres["longitude"] = ds_fullres["longitude"] - 360
    d_perf["success_loading_fullres_data"] = True
except Exception as e:
    d_perf["success_loading_fullres_data"] = False
    d_perf["error_loading_fullres_data"] = e
#%% write a new full resolution storm catalog
# create path for full res storm catalogs if it does not exist
Path(dir_mrms_fullres).mkdir(parents=True, exist_ok=True)
lst_times_to_export = []
if d_perf["success_loading_fullres_data"]:
    try:
        # loop through the coarse storm catalogs and create a new, higher resolution version
        for f in f_ncs_coarse_catalog:
            bm_time = time.time()
            fname = f.split("/")[-1]
            fname_out = dir_mrms_fullres + fname
            ds_strm_crs = xr.open_dataset(f)

            start_time = ds_strm_crs.time.values.min()
            end_time = ds_strm_crs.time.values.max()
            lats = ds_strm_crs.latitude.values
            lons = ds_strm_crs.longitude.values

            ds_subset = ds_fullres.sel(time = slice(start_time, end_time), latitude = slice(min(lats), max(lats)), longitude = slice(min(lons), max(lons)))

            # first upsample the storm catalog and then replace the data with the full resolution data
            ds_strm_crs = ds_strm_crs.resample(time = "5T").asfreq()

            # overwrite coarse rainfall with high resolution rainfall
            ds_strm_crs["rain"] = ds_subset["rainrate"]

            # test
            da_diffs = ds_strm_crs["rain"] - ds_subset["rainrate"]
            diff = da_diffs.sum().values
            if diff != 0:
                sys.exit("Problem exporting full resolution storm catalog.")

            ds_strm_crs.to_netcdf(fname_out, encoding= {"rain":{"zlib":True}})
            elapsed = round((time.time()-bm_time)/60, 2)
            print("it took {} minutes to generate the full resolution storm catalog {}".format(elapsed, fname_out))
            lst_times_to_export.append(elapsed)
        d_perf["success_generate_fullres_catalog"] = True
    except Exception as e:
        d_perf["success_generate_fullres_catalog"] = False
        d_perf["error_generating_fullres_catalog"] = e
d_perf['success'] = True
tot_elapsed = round((time.time()-start_time)/60, 2)
d_perf['total_runtime_min'] = tot_elapsed
d_perf['average_time_to_generate_each_strmcat_min'] = np.mean(lst_times_to_export)

df = pd.DataFrame(d_perf, index = [0])
df.to_csv(dir_mrms_fullres + "_qaqc_yr{}.csv".format(year))