"""
This script consolidates all of the rainfall time series generated by RainyDay
"""
#%% import libraries
from pathlib import Path
import xarray as xr
import pandas as pd
from glob import glob
import time
import shutil
from __utils import *

start_time = time.time()
#%%
lst_f_ncs = glob(fldr_realizations+"*.nc")
bm_time = time.time()
ds_rlztns = xr.open_mfdataset(lst_f_ncs, preprocess = define_dims, engine='h5netcdf')
ds_rlztns.attrs["rain_units"] = "mm_per_hour"
print("Total time elapsed: {}; time to run open_mfdataset on realizations: {}".format(time.time() - start_time, time.time() - bm_time))

# subset to the top 5 largest rain events per year
# compute mean rainfall in mm/hr for each event
ds_mean = ds_rlztns.mean(dim = ["latitude", "longitude", "time"])

# convert from mm/hr to mm
event_duration_hr = (len(ds_rlztns.time)*sst_tstep_min)/60
ds_tot = ds_mean * event_duration_hr # mm / hr * hr

import numpy as np

def find_largest_n_storms_per_year(ds_yr, ds_rlztns = ds_rlztns, nstormsperyear = nstormsperyear):
    lst_ds = []
    year = ds_yr["year"].values
    for rz in ds_yr.realization.values:
        ds_rz = ds_yr.sel(dict(realization = rz))
        top_storm_indices = ds_rz.rain.to_dataframe()["rain"].nlargest(n=nstormsperyear).index.values
        ds_rz_out = ds_rlztns.sel(dict(storm_id = top_storm_indices, year = year, realization = rz))
        # ds_rz_out = ds_rz.sel(dict(storm_id = top_storm_indices, year = year))
        # ds_rz_out = ds_rz_out.assign_coords(dict(realization = rz))
        # ds_rz_out = ds_rz_out.expand_dims("realization")
        # re-define storm_id 
        ds_rz_out['storm_id'] = np.arange(1, nstormsperyear+1)
        # append to list
        lst_ds.append(ds_rz_out)
    ds_out = xr.combine_by_coords(lst_ds)
    return ds_out

ds_tot = ds_tot.groupby("year").map(find_largest_n_storms_per_year)
#%% writing to zarr
bm_time = time.time()
fl_out_zar = dir_zarr_weather_scratch+"weather_combined.zarr"
ds_rlztns = ds_rlztns.chunk(chunks={"realization": 1, "year": 1, "storm_id": 1, "time": 864, "latitude": 2, "longitude": 3})
ds_rlztns.to_zarr(fl_out_zar, mode="w")
print("Total time elapsed: {}; time to export combined rainfall realizations to zarr: {}".format(time.time() - start_time, time.time() - bm_time))

# Load zarr and export to netcdf file
bm_time = time.time()
ds_from_zarr = xr.open_zarr(store=fl_out_zar, chunks={'year':"5000MB"})
ds_from_zarr.to_netcdf(f_rain_realizations, encoding= {"rain":{"zlib":True}})
# delete zarr file
shutil.rmtree(fl_out_zar)
print("Total time elapsed: {}; time to export combined rainfall realizations to netcdf and delete Zarr: {}".format(time.time() - start_time, time.time() - bm_time))

#%% write all rainfall realizations directly to a new netcdf file
# bm_time = time.time()
# ds_rlztns_loaded = ds_rlztns.load()
# print("Total time elapsed: {}; time to load dataset into memory: {}".format(time.time() - start_time, time.time() - bm_time))
# # create path if non-existant
# Path(f_rain_realizations).parent.mkdir(parents=True, exist_ok=True)
# bm_time = time.time()
# ds_rlztns_loaded.to_netcdf(f_rain_realizations, encoding= {"rain":{"zlib":True}})
# print("Total time elapsed: {}; time to export combined realizations to netcdf: {}".format(time.time() - start_time, time.time() - bm_time))