---
title: "Figuring out how to fit multivariate copulas and perform goodness-of-fit tests in R"
output: html_notebook
---

```{r import libraries and define filepaths}
library(fitdistrplus)
library(stats)
library(copula)
library(gofCopula)
library(ggplot2)
library(tidyverse)
library(lmomco) # for plotting positions
source("references/utils.R")

# folder paths
dir_repo = "D:/Dropbox/_GradSchool/_norfolk/stormy/"
dir_sst = paste0(dir_repo , "stochastic_storm_transposition/")
dir_sst_outs <-paste0(dir_sst, "local/outputs/")

# filepaths
f_obs_cdf <- paste0(dir_sst_outs, "b2_F_of_obs_data-cdfvals.csv")
f_sst_cdf <- paste0(dir_sst_outs, "b3_F_of_sst_data-cdfvals.csv")
f_out_sim_wlevel <- paste0(dir_sst_outs, "r_a_sim_wlevel_cdf.csv")
f_out_sim_wlevel_with_emp_cdf <- paste0(dir_sst_outs, "r_a_sim_wlevel_cdf_with_multivariate_empcdf.csv")

# define variables and order then with the storm surge variables first
# which is needed for conditional simulation
vars_all <-  c("max_surge_ft", "surge_peak_after_rain_peak_min", 
               "depth_mm", "mean_mm_per_hr", "max_mm_per_hour")
# define the rainfall variables (the ones used for conditional simulation)
vars_rain <- c("depth_mm", "mean_mm_per_hr", "max_mm_per_hour")

df_obs_cdf <- read_csv(f_obs_cdf) %>% select(vars_all)
df_sst_cdf <- read_csv(f_sst_cdf) %>%
  mutate(max_surge_ft = 9999, surge_peak_after_rain_peak_min = 9999 )%>%
  select(vars_all)

```

```{r Fitting and Conditional Simulation using CDVineCopulaConditional Library}
# https://cran.rstudio.com/web/packages/CDVineCopulaConditional/index.html
library(CDVineCopulaConditional)

y_obs <- as.matrix(df_obs_cdf)
x_sst_cond <- as.matrix(df_sst_cdf)



RVM <- CDVineCondFit(y_obs ,Nx=length(vars_rain),treecrit="AIC",type="CVine-DVine",selectioncrit="AIC",
                     rotations = TRUE)
# inspect fitted copula object
summary(RVM)


# conditional sampling from a D-Vine
## Set the values of the conditioning variables as those used for the calibration.
## these are pulled directly from the documentation
if(RVM$type == "D-vine"){
  # From docs:
  ## For D-vine: data corresponding to the conditioning variable 
  ## whose index is in RVM$Matrix[i,i], are in i-th column of Condition.
  cond1 <- x_sst_cond[,RVM$Matrix[1,1]]
  cond2 <- x_sst_cond[,RVM$Matrix[2,2]]
  cond3 <- x_sst_cond[,RVM$Matrix[3,3]]
  condition <- cbind(cond1,cond2,cond3)
}

if(RVM$type == "C-vine"){
  # For C-vine: data corresponding to the conditioning
  # variable whose index is in RVM$Matrix[i,i], are in [(d+1)-i]-th column of
  # Condition.
  d=dim(RVM$Matrix)[1]
  cond1 <- x_sst_cond[,RVM$Matrix[(d+1)-1,(d+1)-1]]
  cond2 <- x_sst_cond[,RVM$Matrix[(d+1)-2,(d+1)-2]]
  cond3 <- x_sst_cond[,RVM$Matrix[(d+1)-3,(d+1)-3]]
  condition <- cbind(cond1,cond2,cond3)
}
```

```{r Conditional Simulation}
set.seed(3) # 3
Sim <- CDVineCondSim(RVM,condition)

validate_col_order <- sum(Sim[,3:5] - x_sst_cond[,3:5])
if(validate_col_order != 0){
  print("ERROR! SIMULATION COLUMNS ARE OUT OF ORDER.")
}


# Plot the simulated variables over the observed
Sim <- data.frame(Sim)
obs <- data.frame(y_obs)
colnames(Sim) <- colnames(y_obs)
n_to_plot <- 95
overplot(Sim[1:n_to_plot,],obs[1:n_to_plot,], method = "kendall") # data is in light gray

# export simulated data to csv
tibble(Sim) %>% write_csv(f_out_sim_wlevel)
```
```{r}
# building empirical CDF of simulated events
# pasted from https://github.com/ben519/mltools/blob/22d9c397aad1e7bc9d01366d4bcc76f39ae0d579/R/empirical_cdf.R#L19
empirical_cdf <- function(x, ubounds){
  # Build the empirical_cdf of the given data
  # CDF points are the points given by ubounds
  # x can be a numeric vector or a data.table
  # ubounds can be a numeric vector or a data.table, but must correspond to x accordingly
  
  #--------------------------------------------------
  # Hack to pass 'no visible binding for global variable' notes from R CMD check
  
  BoundID <- NULL
  N <- NULL
  N.cum <- NULL
  
  #--------------------------------------------------
  # Check the input
  
  if(!is.numeric(x) & !is.data.table(x))
    stop("x must be numeric or a data.table object")
  
  if(!is.numeric(ubounds) & !is.data.table(ubounds))
    stop("ubounds must be numeric or a data.table object")
  
  if(is.data.table(ubounds)){
    if(ncol(ubounds) > 1){
      if(!is.data.table(x)){
        stop("If ubounds is a data.table with multiple columns, x should be a data.table object with corresponding columns")
      } else if(length(setdiff(colnames(ubounds), colnames(x))) > 0)
        stop("ubounds contains columns not found in x")
    }
  }
  
  if(is.data.table(x)){
    if(ncol(x) > 1 & !is.data.table(ubounds)){
      stop("If x is a data.table with multiple columns, ubounds must be a data.table with at least one column otherwise it is unclear which column of x ubounds relates to.")
    }
  }
  
  #--------------------------------------------------
  
  # Build ubounds
  if(!is.data.table(ubounds)){
    ubounds <- data.table(UpperBound = ubounds)
    if(is.data.table(x)) setnames(ubounds, "UpperBound", colnames(x))  # Here, colnames(x) should be one value
  }
  
  # If x is a vector
  if(mode(x) == "numeric"){
    
    # Convert x to a data.table object
    x <- data.table(x)
    setnames(x, names(ubounds))
  }
  
  #--------------------------------------------------
  # From here on, assume x is a data.table
  
  # Convert columns of x and ubounds to numeric. This is to fix a data.table bug involving rolling joins on integer columns
  x <- x[, colnames(ubounds), with=F]
  ubounds <- copy(ubounds)
  for(col in colnames(ubounds)){
    set(x, j=col, value=as.numeric(x[[col]]))
    set(ubounds, j=col, value=as.numeric(ubounds[[col]]))
  }
  
  # Reduce to uniques
  uboundsUniques <- unique(ubounds)
  
  # Build a copy of x
  binned <- copy(x[, names(uboundsUniques), with=FALSE])
  
  # For each binning column, match each row of x to the nearest boundary above
  for(col in names(uboundsUniques)){
    uboundDT <- unique(data.table(uboundsUniques[[col]], uboundsUniques[[col]]))
    setnames(uboundDT, c(col, paste0("Bound.", col)))
    binned <- uboundDT[binned, on=col, roll=-Inf, nomatch=0]
  }
  
  # Aggregate to unique tuples based on Bound.* columns
  binned.uniques <- binned[, .N, keyby=eval(paste0("Bound.", names(ubounds)))]
  setnames(binned.uniques, paste0("Bound.", names(ubounds)), names(ubounds))
  
  # Get the count of samples directly below EVERY bound
  uboundsUniques <- binned.uniques[uboundsUniques, on=names(ubounds)]
  uboundsUniques[is.na(N), N := 0]
  
  # Counting (see https://stackoverflow.com/a/40583817/2146894)
  if(ncol(ubounds) == 1){
    uboundsUniques[, N.cum := cumsum(N)]
  } else{
    fixedCols <- names(ubounds)[-1]
    uboundsUniques[, N.cum := cumsum(N), by=fixedCols]
    
    for(i in seq_len(ncol(ubounds) - 1)){
      i = i + 1
      fixedCols <- names(ubounds)[-i]
      uboundsUniques[, N.cum := cumsum(N.cum), by=fixedCols]
    }
  }
  
  # Cleanup
  samples <- nrow(x)
  uboundsUniques[, `:=`(N = NULL, CDF = N.cum/samples)]
  
  # Join back to ubounds in case of potential duplicate ubounds
  ubounds <- uboundsUniques[ubounds, on=names(ubounds)]
  
  return(ubounds[])
}
```


```{r}
# testing empirical_cdf functuion
dt <- data.table(x=c(0.3, 1.3, 1.4, 3.6), y=c(1.2, 1.2, 3.8, 3.9))
empirical_cdf(dt$x, ubounds=1:4)
empirical_cdf(dt, ubounds=CJ(x = 1:4, y = 1:4))
```

```{r}
# compute the empirical CDF value of each compound event
library("data.table")

dt_sim = data.table(Sim)

emp_cdf_sim <- empirical_cdf(dt_sim, dt_sim[1,])

dt_results <- data.table()

# Loop through all rows
for (i in 1:nrow(dt_sim)) {
  # print(i)
  # Accessing elements in each row
  row_values <- dt_sim[i, ]
  
  emp_cdf_sim <- empirical_cdf(dt_sim, row_values)
  
  dt_results <- rbind(dt_results, emp_cdf_sim)
  
  # Append the squared_age to the result_list
  # result_list <- c(result_list, squared_age)
}

# export simulated data to csv
tibble(dt_results) %>% write_csv(f_out_sim_wlevel_with_emp_cdf)
```

